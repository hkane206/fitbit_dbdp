{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import unittest\n",
    "from unittest import TestCase\n",
    "\n",
    "# For testing in an ipynb:\n",
    "# import importlib\n",
    "# importlib.reload(FitBit)\n",
    "# Run second line in a cell everytime you make changes to FitBit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitBit:\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initialize FitBit object and load all data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            The path to the folder containing all data collected from FitBit.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        FitBit\n",
    "            An instance of the FitBit class with various DataFrames loaded.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize file_path attribute\n",
    "        self.file_path = file_path\n",
    "\n",
    "        # Load various types of data into respective attributes\n",
    "        # Using load_and_concat function to fetch and concatenate data files matching the pattern\n",
    "        # Each attribute will hold a DataFrame containing the respective type of data\n",
    "\n",
    "        self.sleep = self.load_and_concat('/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/sleep-*.json')\n",
    "        self.energy = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/calories-*.json\")\n",
    "        self.steps = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/steps-*.json\")\n",
    "        self.distance = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/distance-*.json\")\n",
    "        self.oxygen = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/estimated_oxygen_variation-*.json\")\n",
    "        self.resting_heart_rate = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/resting_heart_rate-*.json\")\n",
    "        self.heart_rate = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-*.json\")\n",
    "        self.respiration_rate = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/distance-*.json\")\n",
    "        self.sleep_stage = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/sleep-*.json\")\n",
    "        self.floors_climbed = self.load_and_concat(\"/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/altitude-*.json\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load(self, file_path):\n",
    "        \"\"\"\n",
    "        Load data from a specified file path.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "            The path to the data file.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            The loaded data as a pandas DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        # Update the file path\n",
    "        self.file_path = file_path\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(self.file_path):\n",
    "\n",
    "            # Get file format (csv or json)\n",
    "            file = self.file_path.split('/')[-1]\n",
    "            file_name, file_format = file.split('.')\n",
    "\n",
    "            # Load data depending on file format\n",
    "            if file_format == 'csv':\n",
    "                print(f\"CSV data loaded from {self.file_path}\")\n",
    "                return pd.read_csv(self.file_path)\n",
    "            elif file_format == 'json':\n",
    "                print(f\"JSON data loaded from {self.file_path}\")\n",
    "                return pd.read_json(self.file_path)\n",
    "            else:\n",
    "                print(f\"Unsupported file format: {file_format}\")\n",
    "        else:\n",
    "            print(f\"The path {self.file_path} does not exist.\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_and_concat(self, pattern):\n",
    "        \"\"\"\n",
    "        Load and concatenate multiple files that match the given file name pattern.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        pattern : str\n",
    "            The file name pattern to search for.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A DataFrame consisting of concatenated data from all matched files.\n",
    "            Returns an empty DataFrame if no data was found.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get list of all file paths that match the pattern\n",
    "        file_paths = glob.glob(os.path.join(self.file_path, pattern))\n",
    "        data_frames = []\n",
    "\n",
    "        # Loop through all matched file paths\n",
    "        for file_path in file_paths:\n",
    "            # Load each file into a DataFrame using the load method\n",
    "            df = self.load(file_path)\n",
    "            # Append DataFrame to the list if it's not None\n",
    "            if df is not None:\n",
    "                data_frames.append(df)\n",
    "\n",
    "        # Concatenate all DataFrames if the list is not empty\n",
    "        if data_frames:\n",
    "            return pd.concat(data_frames, ignore_index=True)\n",
    "        else:\n",
    "            # Return an empty DataFrame if no data was found\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/sleep-2023-09-19.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/calories-2023-09-19.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/steps-2023-09-19.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/distance-2023-09-19.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/resting_heart_rate-2023-09-19.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-2023-09-25.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-2023-09-24.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-2023-09-23.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-2023-09-22.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-2023-09-21.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-2023-09-20.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/heart_rate-2023-09-26.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/distance-2023-09-19.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/sleep-2023-09-19.json\n",
      "JSON data loaded from /Users/harrisonkane/Desktop/BME/fitbit_dbdp/data/Global Export Data/altitude-2023-09-19.json\n",
      "                 dateTime                         value\n",
      "0     2023-09-25 04:00:02  {'bpm': 62, 'confidence': 2}\n",
      "1     2023-09-25 04:00:07  {'bpm': 62, 'confidence': 2}\n",
      "2     2023-09-25 04:00:17  {'bpm': 67, 'confidence': 2}\n",
      "3     2023-09-25 04:00:22  {'bpm': 68, 'confidence': 2}\n",
      "4     2023-09-25 04:00:32  {'bpm': 69, 'confidence': 2}\n",
      "...                   ...                           ...\n",
      "72032 2023-09-27 03:58:43  {'bpm': 69, 'confidence': 1}\n",
      "72033 2023-09-27 03:58:53  {'bpm': 67, 'confidence': 1}\n",
      "72034 2023-09-27 03:58:58  {'bpm': 68, 'confidence': 1}\n",
      "72035 2023-09-27 03:59:08  {'bpm': 69, 'confidence': 1}\n",
      "72036 2023-09-27 03:59:23  {'bpm': 69, 'confidence': 1}\n",
      "\n",
      "[72037 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# Unit Test\n",
    "#####\n",
    "\n",
    "file_path = '/Users/harrisonkane/Desktop/BME/fitbit_dbdp/data'\n",
    "fitbit= FitBit(file_path)\n",
    "\n",
    "print(fitbit.heart_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self,data,column):\n",
    "        self.data = data\n",
    "        self.column = column\n",
    "\n",
    "    @classmethod\n",
    "    def imputeData(self, method='mean'):\n",
    "        \"\"\"\n",
    "        Impute missing values in the data.\n",
    "        Args:\n",
    "            data (pd.DataFrame): Input data containing missing values.\n",
    "        Returns:\n",
    "            pd.DataFrame: Data with missing values imputed.\n",
    "        \"\"\"\n",
    "\n",
    "        if method == 'mean':\n",
    "            self.data[self.column] = self.data[self.column].fillna(self.data[self.column].mean())\n",
    "        elif method == 'median':\n",
    "            self.data[self.column] = self.data[self.column].fillna(self.data[self.column].median())\n",
    "        elif method == 'zero':\n",
    "            self.data[self.column] = self.data[self.column].fillna(0)\n",
    "        return self.data\n",
    "\n",
    "    @classmethod\n",
    "    def sampleData(self, downsample=True, sample_rate=0):\n",
    "        \"\"\"\n",
    "        Sample the data, optionally downsampling it.\n",
    "        Args:\n",
    "            data (pd.DataFrame): Input data for sampling.\n",
    "            downsample (bool): Whether to downsample the data.\n",
    "        Returns:\n",
    "            pd.DataFrame: Sampled data.\n",
    "        \"\"\"\n",
    "        \n",
    "        if downsample == True:\n",
    "            sampled_data = self.data.sample(frac=sample_rate, random_state=1)\n",
    "        else: \n",
    "            if not isinstance(self.data.index, pd.DatetimeIndex):\n",
    "                self.data.index = pd.to_datetime(self.data.index)\n",
    "            data_index = self.data.index\n",
    "            sampled_data = self.data.resample(rule=str(sample_rate)+'D').asfreq()\n",
    "            sampled_data.interpolate(method='linear', inplace=True)\n",
    "            sampled_data = sampled_data.reindex(data_index, method='nearest')\n",
    "        return sampled_data\n",
    "\n",
    "    @classmethod\n",
    "    def covertTime(self, time_col, timezone='UTC'):\n",
    "        \"\"\"\n",
    "        Convert a specific column in the data to a time format.\n",
    "        Args:\n",
    "            data (pd.DataFrame): Input data containing time data.\n",
    "            time_col (str): Name of the time column to convert.\n",
    "        Returns:\n",
    "            pd.DataFrame: Data with the time column converted.\n",
    "        \"\"\"\n",
    "        # FOR FUTURE: with standard format, shouldn't need to ask for time_col\n",
    "        # As all DataFrames will have same name for time column\n",
    "        # Also won't need to convert to datetime because will already be converted\n",
    "\n",
    "        # Ensure the specified column exists in the DataFrame\n",
    "        if time_col not in self.data.columns:\n",
    "            raise ValueError(f\"Column '{time_col}' not found in the DataFrame.\")\n",
    "\n",
    "        # Convert column to DateTime format (although it already should be in DateTime format)\n",
    "        self.data[time_col] = pd.to_datetime(self.data[time_col], errors='coerce')\n",
    "\n",
    "        # Apply the specified timezone (default is 'UTC')\n",
    "        self.data[time_col] = self.data[time_col].dt.tz_localize(timezone)\n",
    "\n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Unit Test\n",
    "#####\n",
    "\n",
    "data = pd.DataFrame({'A': [1, 2, None, 4, 5], 'B': [5, 4, 3, None, 1]})\n",
    "preprocessor = Preprocess(data, 'A')\n",
    "\n",
    "assert preprocessor.imputeData('mean').isnull().sum().sum(), 0\n",
    "assert preprocessor.imputeData('median').isnull().sum().sum(), 0\n",
    "assert preprocessor.imputeData('zero').isnull().sum().sum(), 0\n",
    "\n",
    "# Test sampleData method for downsampling\n",
    "downsampled_data = preprocessor.sampleData(downsample=True, sample_rate=0.5)\n",
    "assert downsampled_data.shape[0] < data.shape[0]\n",
    "\n",
    "# # Test sampleData method for upsampling\n",
    "upsampled_data = preprocessor.sampleData(downsample=False, sample_rate=2)\n",
    "upsampled_data\n",
    "# assert upsampled_data.shape[0] > data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDA:\n",
    "    def __init__(self,data):\n",
    "        ## Assume it is already processed\n",
    "        self.data = data\n",
    "        self.interval = None\n",
    "        self.mean = None\n",
    "        self.median = None\n",
    "        self.std = None\n",
    "    \n",
    "    @classmethod\n",
    "    def describeData(self):\n",
    "        self.mean = np.mean(self.data)\n",
    "        self.median = np.median(self.data)\n",
    "        self.interval = np.max(self.data) - np.min(self.data)\n",
    "        self.std = np.std(self.data)\n",
    "        print(f\"Mean: {self.mean:.5f}\")\n",
    "        print(f\"Median: {self.median:.5f}\")\n",
    "        print(f\"Interval: {self.interval:.5f}\")\n",
    "        print(f\"Standard Deviation: {self.std:.5f}\")\n",
    "\n",
    "    @classmethod\n",
    "    def dataDistribution(self):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.distplot(self.data, bins=30, kde=False, color='blue')\n",
    "        plt.title('Data Distribution Plot')\n",
    "        plt.xlabel('Values')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "    \n",
    "    @classmethod\n",
    "    def detectOutliers(self):\n",
    "        iqr = np.percentile(self.data, 75) - np.percentile(self.data, 25)\n",
    "        lower_bound = np.percentile(self.data, 25) - 1.5 * iqr\n",
    "        upper_bound = np.percentile(self.data, 75) + 1.5 * iqr\n",
    "        outliers = [x for x in self.data if x < lower_bound or x > upper_bound]\n",
    "        print(\"Outliers:\", outliers)\n",
    "    \n",
    "    @classmethod\n",
    "    def correlationAnalysis(self,other_data):\n",
    "    # Add code to perform correlation analysis\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Unit Test\n",
    "#####\n",
    "\n",
    "data = np.random.normal(0, 1, 1000)\n",
    "eda = EDA(data)\n",
    "eda.describeData()\n",
    "eda.dataDistribution()\n",
    "eda.detectOutliers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('fitbit': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51a67541d439c69df5363ee44e1645bc59903267799ca2fd91b2dc45053bde71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
